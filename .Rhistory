nrow(train_data$spec)
nrow(train_data$class)
length(train_data)
length(train_data$spec)
dim(train_array) <- c(n_time, (n_freq/2), length(train_data$spec), 1)
dim(train_array)
image(z=train_array[,,1,1])
# Model
train_array <- unlist(t(train_data$spec))
dim(train_array) <- c(n_time, n_freq, length(train_data$spec), 1)
# Reorder dimensions
train_array <- aperm(train_array, c(3, 1, 2, 4))
dim(train_array) <- c(n_time, n_freq, length(train_data$spec), 1)
dim(train_array) <- c(n_time, n_freq/2, length(train_data$spec), 1)
# Reorder dimensions
train_array <- aperm(train_array, c(3, 1, 2, 4))
# Build training  and test arrays
train_array <- unlist(t(train_data$spec))
dim(train_array) <- c(n_time, n_freq/2, length(train_data$spec), 1)
test_array <- unlist(t(test_data$spec))
dim(test_array) <- c(n_time, n_freq/2, length(test_data$spec), 1)
# Reorder dimensions
train_array <- aperm(train_array, c(3, 1, 2, 4))
test_array <- aperm(test_array, c(3, 1, 2, 4))
image(z=t(test_array[2,,,1]))
image(z=(test_array[2,,,1]))
image(z=(test_array[4,,,1]))
help layer_conv_2d()
help(layer_conv_2d())
help(layer_conv_2d
)
model <- keras_model_sequential()
model %>%
layer_conv_2d(kernel_size=c(3,3), filter=32, activation='relu',
padding='same', input_shape=c(n_time, n_freq/2, 1),
data_format='channels last') %>%
layer_conv_2d(kernel_size=c(3,3), filter=32, activation='relu',
padding='valid') %>%
layer_max_pooling_2d(pool_size=2) %>%
layer_dropout(rate=0.25) %>%
layer_conv_2d(kernel_size=c(3,3), filter=64, strides=2,
activation='relu', padding='same') %>%
layer_conv_2d(kernel_size=c(3,3), filter=64, activation='relu',
padding='valid') %>%
layer_max_pooling_2d(pool_size=2) %>%
layer_dropout(rate=0.25) %>%
layer_flatten() %>%
layer_dense(units=50, activation='relu') %>%
layer_dropout(rate=0.25) %>%
layer_dense(units=1, activation='sigmoid')
model %>%
layer_conv_2d(kernel_size=c(3,3), filter=32, activation='relu',
padding='same', input_shape=c(n_time, n_freq/2, 1),
data_format='channels_last') %>%
layer_conv_2d(kernel_size=c(3,3), filter=32, activation='relu',
padding='valid') %>%
layer_max_pooling_2d(pool_size=2) %>%
layer_dropout(rate=0.25) %>%
layer_conv_2d(kernel_size=c(3,3), filter=64, strides=2,
activation='relu', padding='same') %>%
layer_conv_2d(kernel_size=c(3,3), filter=64, activation='relu',
padding='valid') %>%
layer_max_pooling_2d(pool_size=2) %>%
layer_dropout(rate=0.25) %>%
layer_flatten() %>%
layer_dense(units=50, activation='relu') %>%
layer_dropout(rate=0.25) %>%
layer_dense(units=1, activation='sigmoid')
model <- keras_model_sequential()
model %>%
layer_conv_2d(kernel_size=c(3,3), filter=32, activation='relu',
padding='same', input_shape=c(n_time, n_freq/2, 1),
data_format='channels_last') %>%
layer_conv_2d(kernel_size=c(3,3), filter=32, activation='relu',
padding='valid') %>%
layer_max_pooling_2d(pool_size=2) %>%
layer_dropout(rate=0.25) %>%
layer_conv_2d(kernel_size=c(3,3), filter=64, strides=2,
activation='relu', padding='same') %>%
layer_conv_2d(kernel_size=c(3,3), filter=64, activation='relu',
padding='valid') %>%
layer_max_pooling_2d(pool_size=2) %>%
layer_dropout(rate=0.25) %>%
layer_flatten() %>%
layer_dense(units=50, activation='relu') %>%
layer_dropout(rate=0.25) %>%
layer_dense(units=1, activation='sigmoid')
summary(model)
model %>% compile(loss='binary_crossentropy',
optimizer='adam', metrics=c('accuracy'))
history <- model %>% fit(x=train_array, y=train_data$class_id,
epochs=30, batch_size=100, validation_split=0.2)
source('C:/Code/Git/PuzzleCounter/speech_trainer_command_data.R', echo=TRUE)
source('C:/Code/Git/PuzzleCounter/speech_trainer_command_data.R', echo=TRUE)
# model specified by tensorflow post
model %>%
layer_conv_2d(input_shape=c(n_time, n_freq/2,1), filters=32,
kernel_size=c(3,3), activation='relu') %>%
layer_max_pooling_2d(pool_size=c(2,2)) %>%
layer_conv_2d(filters=64, kernel_size=c(3,3), activation='relu') %>%
layer_max_pooling_2d(pool_size=c(2,2)) %>%
layer_conv_2d(filters=128, kernel_size=c(3,3), activation='relu') %>%
layer_max_pooling_2d(pool_size=c(2,2)) %>%
layer_conv_2d(filters=256, kernel_size=c(3,3), activation='relu') %>%
layer_max_pooling_2d(pool_size=c(2,2)) %>%
layer_dropout(rate=0.25) %>%
layer_flatten() %>%
layer_dense(units=128, activation='relu') %>%
layer_dropout(rate=0.5) %>%
layer_dense(units=30, activation='softmax')
model <- keras_model_sequential()
# model specified by tensorflow post
model %>%
layer_conv_2d(input_shape=c(n_time, n_freq/2,1), filters=32,
kernel_size=c(3,3), activation='relu') %>%
layer_max_pooling_2d(pool_size=c(2,2)) %>%
layer_conv_2d(filters=64, kernel_size=c(3,3), activation='relu') %>%
layer_max_pooling_2d(pool_size=c(2,2)) %>%
layer_conv_2d(filters=128, kernel_size=c(3,3), activation='relu') %>%
layer_max_pooling_2d(pool_size=c(2,2)) %>%
layer_conv_2d(filters=256, kernel_size=c(3,3), activation='relu') %>%
layer_max_pooling_2d(pool_size=c(2,2)) %>%
layer_dropout(rate=0.25) %>%
layer_flatten() %>%
layer_dense(units=128, activation='relu') %>%
layer_dropout(rate=0.5) %>%
layer_dense(units=30, activation='softmax')
summary(model)
ntrain <- 100
source('C:/Code/Git/PuzzleCounter/speech_trainer_command_data.R', echo=TRUE)
source('C:/Code/Git/PuzzleCounter/speech_trainer_command_data.R', echo=TRUE)
source('C:/Code/Git/PuzzleCounter/speech_trainer_command_data.R', echo=TRUE)
source('C:/Code/Git/PuzzleCounter/speech_trainer_command_data.R', echo=TRUE)
hold = tf$one_hot(test_data$class_id, 30L)
View(hold)
hold[[1]]
help(ftst)
help(stft)
helpt(tf.signal.stft)
helpt(tf$signal$stft)
help(tf$signal$stft)
help(stft)
tf$signal$stft()
help(stft())
tf$signal$stft(snd, 320, 160, pad_end=TRUE)
typeof(snd)
tf$signal$stft(snd, 320, 160)
tf$signal$stft(snd, 320, 160, pad_end=TRUE)
library(stringr)
library(dplyr)
library(tfdatasets)
library(tuneR)
library(signal)
library(pbapply)
library(keras)
# from fs (file system operations) package borrow dir_ls
files <- fs::dir_ls(
path = "data/speech_commands_v0.01/",
recurse = TRUE,
glob = "*.wav"
)
# keep all files except those with background_noise in the name
files <- files[!str_detect(files, "background_noise")]
# make a tibble of filenames, class (word spoken) of each
# file and class as an integer
df <- tibble(
fname = files,
class = fname %>% str_extract("1/.*/") %>%
str_replace_all("1/", "") %>%
str_replace_all("/", ""),
class_id = class %>% as.factor() %>% as.integer() - 1L
)
# set up training and test sets
set.seed(1)
ntrain <- 1000
# set up training and test sets
set.seed(1)
ntrain <- 100
ntest <- 30
all <- seq(nrow(df))
train <- sample(all, ntrain, replace=FALSE)
test <- sample(all[-train], ntest, replace=FALSE)
# set up spectrogram creation
window_size_ms <- 30 # window in ms
window_stride_ms <- 10 # step size between windows in ms
# note: files should have 16000 samples per second
window <- as.integer(16*window_size_ms) # samples per window
stride <- as.integer(16*window_stride_ms) # samples per stride
overlap <- window - stride # overlap of each window
n_freq <- as.integer(2^(trunc(log(window, 2)+1)))
n_chunks <- length(seq(window_size/2, 16000-window_size/2, stride))
source('C:/Code/Git/PuzzleCounter/speech_trainer_command_data.R', echo=TRUE)
source('C:/Code/Git/PuzzleCounter/speech_trainer_command_data.R', echo=TRUE)
ds_train
length(ds_train)
ds_train@fname
ds_train$fname
ds$fname
source('C:/Code/Git/PuzzleCounter/speech_trainer_command_data.R', echo=TRUE)
source('C:/Code/Git/PuzzleCounter/speech_trainer_command_data.R', echo=TRUE)
source('C:/Code/Git/PuzzleCounter/speech_trainer_command_data.R', echo=TRUE)
source('C:/Code/Git/PuzzleCounter/speech_trainer_command_data.R', echo=TRUE)
df$fname
ds<-tensor_slices_dataset(df)
source('C:/Code/Git/PuzzleCounter/speech_trainer_command_data.R', echo=TRUE)
source('C:/Code/Git/PuzzleCounter/speech_trainer_command_data.R', echo=TRUE)
source('C:/Code/Git/PuzzleCounter/speech_trainer_command_data.R', echo=TRUE)
source('C:/Code/Git/PuzzleCounter/speech_trainer_command_data.R', echo=TRUE)
source('C:/Code/Git/PuzzleCounter/speech_trainer_command_data.R', echo=TRUE)
View(ds_train)
View(ds_train)
source('C:/Code/Git/PuzzleCounter/speech_trainer_command_data.R', echo=TRUE)
source('C:/Code/Git/PuzzleCounter/speech_trainer_command_data.R', echo=TRUE)
source('C:/Code/Git/PuzzleCounter/speech_trainer_command_data.R', echo=TRUE)
source('C:/Code/Git/PuzzleCounter/speech_trainer_command_data.R', echo=TRUE)
ds_train$enumerate
source('C:/Code/Git/PuzzleCounter/speech_trainer_command_data.R', echo=TRUE)
print(ds_train)
print(df)
source('C:/Code/Git/PuzzleCounter/speech_trainer_command_data.R', echo=TRUE)
print(ds_train)
audio_binary <- tf$io$read_file(df$fname[1])
View(audio_binary)
print(audio_binary)
wav = tr$audio$decode_wav(audio_binary, desired_channels=1)
wav = tf$audio$decode_wav(audio_binary, desired_channels=1)
spectrogram=tf$signal$stft(wav$audio, window_size=window, frame_step=stride)
spectrogram=tf$signal$stft(wav$audio, frame_length=window, frame_step=stride)
spectrogram=tf$signal$stft(wav$audio, frame_length=512, frame_step=stride)
typeof(512)
typeof(stride)
spectrogram=tf$signal$stft(wav$audio, frame_length=as.integer(512), frame_step=stride)
spectrogram$numpy
spectrogram$graph
source('C:/Code/Git/PuzzleCounter/speech_trainer_command_data.R', echo=TRUE)
library(keras)
use_implementation('tensorflow')
library(keras)
use_implementation('tensorflow')
library(tensorflow)
tfe_enable_eager_execution
tfe_enable_eager_execution(device_policy='silent')
tfe_enable_eager_execution()
library(keras)
use_implementation('tensorflow')
library(tensorflow)
tfe_enable_eager_execution()
library(keras)
use_implementation('tensorflow')
library(tensorflow)
tfe_enable_eager_execution()
tfe_enable_eager_execution(device_policy='silent')
fname <- 'data/speech_commands_v0.01/bird/00b01445_nohash_0.wav'
fname <- 'data/speech_commands_v0.01/bird/00b01445_nohash_0.wav'
wav <- tf$audio$decode_wav(tf$read_file(fname))
wav <- tf$audio$decode_wav(tf$io$read_file(fname))
sampling_rate <- wav$sample_rate %>% as.numeric()
sampling_rate
samples <- wav$audio
samples <- samples %>% tf$transpose(perm=c(1L, 0L))
samples
window_size <- 30
window_size_ms <- 30
window_stride_ms <- 10
samples_per_window <- sampling_rate*window_size_ms/1000
strid_samples <- sampling_rate*window_stride_ms/1000
stft_out <- tf$signal$stft(
samples,
frame_length=as.integer(samples_per_window),
frame_step=as.integer(stride_samples))
stride_samples <- sampling_rate*window_stride_ms/1000
stft_out <- tf$signal$stft(
samples,
frame_length=as.integer(samples_per_window),
frame_step=as.integer(stride_samples))
stft_out
n_periods <- length(seq(samples_per_window/2,
sampling_rate-samples_per_window/2,
stride_samples))
fft_size <- as.integer(2^trunc(log(samples_per_window, 2))+1)
magnitude_spectrograms <- tf$abs(stft_out)
magnitude_spectrograms
log_magnitude_spectrograms <- tf$math$log(magnitude_spectrograms + 1e-6)
log_magnitude_spectrograms
plot(log_magnitude_spectrograms)
image(z=log_magnitude_spectrograms)
lms_matrix <- as.matrix(log_magnitude_spectrograms)
image(z=lms_matrix)
lms_matrix <- as.array(log_magnitude_spectrograms)
image(z=lms_matrix)
lms_matrix <- as.matrix(log_magnitude_spectrograms)
lms_matrix <- as.matrix(log_magnitude_spectrograms, nrow=n_periods)
image(z=lms_matrix)
lms_matrix <- as.matrix(log_magnitude_spectrograms, nrow=n_periods)
image(z=lms_matrix)
lms_matrix <- as.matrix(log_magnitude_spectrograms[1,,], nrow=n_periods)
image(z=lms_matrix)
lms_matrix <- as.matrix(log_magnitude_spectrograms[1,,], col=n_periods)
image(z=lms_matrix)
lms_matrix <- as.matrix(log_magnitude_spectrograms[1,,])
image(z=lms_matrix)
# from fs (file system operations) package borrow dir_ls
files <- fs::dir_ls(
path = "data/speech_commands_v0.01/",
recurse = TRUE,
glob = "*.wav"
)
# keep all files except those with background_noise in the name
files <- files[!str_detect(files, "background_noise")]
# make a tibble of filenames, class (word spoken) of each
# file and class as an integer
df <- tibble(
fname = files,
class = fname %>% str_extract("1/.*/") %>%
str_replace_all("1/", "") %>%
str_replace_all("/", ""),
class_id = class %>% as.factor() %>% as.integer() - 1L
)
# set up training and test sets
set.seed(1)
ntrain <- 300
ntest <- 300
all <- seq(nrow(df))
train <- sample(all, ntrain, replace=FALSE)
test <- sample(all[-train], ntest, replace=FALSE)
## open wav and make spectrogram
# following https://hansenjohnson.org/post/spectrograms-in-r/
library(tuneR)
library(signal)
library(oce)
filename <- 'data/speech_commands_v0.01/bed/00176480_nohash_0.wav'
n = train[1]
k = 1
evens = seq(k, 16000, k)
# read in audio file
data <- readWave(df$fname[n])
# extract signal
snd <- data@left
snd <- snd[evens]
# determine duration
dur = length(snd)/data@samp.rate*k
# determine sample rate
fs <- data@samp.rate/k
# window size in points
window <- 600
# number of points to use for the fft
nfft = as.integer(2^(trunc(log(window, 2))+1))
# window overlap in points
overlap <-200
# create spectrogram
spec <- specgram(x=snd, n=nfft, Fs=fs, window=window,
overlap=overlap)
P <- log10(abs(spec$S)+0.01)
image(x=spec$t, y=spec$f, z=t(P),
ylab='Frequency[Hz]', xlab='Time[s]',
main=paste(df$class[n], " ", window), zlim=c(-0.6, 6.1))
spec_vec <- as.vector(t(P))
remat <- matrix(spec_vec, ncol = nrow(P))
fname <- df$fname[n]
wav <- tf$audio$decode_wav(tf$io$read_file(fname))
sampling_rate <- wav$sample_rate %>% as.numeric()
sampling_rate
samples <- wav$audio
samples <- samples %>% tf$transpose(perm=c(1L, 0L))
samples
window_size_ms <- 30
window_stride_ms <- 10
samples_per_window <- sampling_rate*window_size_ms/1000
stride_samples <- sampling_rate*window_stride_ms/1000
n_periods <- length(seq(samples_per_window/2,
sampling_rate-samples_per_window/2,
stride_samples))
fft_size <- as.integer(2^trunc(log(samples_per_window, 2))+1)
stft_out <- tf$signal$stft(
samples,
frame_length=as.integer(samples_per_window),
frame_step=as.integer(stride_samples))
stft_out
magnitude_spectrograms <- tf$abs(stft_out)
magnitude_spectrograms
log_magnitude_spectrograms <- tf$math$log(magnitude_spectrograms + 1e-6)
log_magnitude_spectrograms
lms_matrix <- as.matrix(log_magnitude_spectrograms[1,,])
image(z=lms_matrix)
source('C:/Code/Git/PuzzleCounter/test_script.R', echo=TRUE)
source('C:/Code/Git/PuzzleCounter/test_script.R', echo=TRUE)
source('C:/Code/Git/PuzzleCounter/test_script.R', echo=TRUE)
source('C:/Code/Git/PuzzleCounter/test_script.R', echo=TRUE)
source('C:/Code/Git/PuzzleCounter/test_script.R', echo=TRUE)
source('C:/Code/Git/PuzzleCounter/test_script.R', echo=TRUE)
fname <- 'data/speech_commands_v0.01/bird/1746d7b6_nohash_0.wav'
#fname <- df$fname[n]
wav <- tf$audio$decode_wav(tf$io$read_file(fname))
sampling_rate <- wav$sample_rate %>% as.numeric()
sampling_rate
samples <- wav$audio
samples <- samples %>% tf$transpose(perm=c(1L, 0L))
samples
window_size_ms <- 30
window_stride_ms <- 10
samples_per_window <- sampling_rate*window_size_ms/1000
stride_samples <- sampling_rate*window_stride_ms/1000
n_periods <- length(seq(samples_per_window/2,
sampling_rate-samples_per_window/2,
stride_samples))
fft_size <- as.integer(2^trunc(log(samples_per_window, 2))+1)
stft_out <- tf$signal$stft(
samples,
frame_length=as.integer(samples_per_window),
frame_step=as.integer(stride_samples))
stft_out
magnitude_spectrograms <- tf$abs(stft_out)
magnitude_spectrograms
log_magnitude_spectrograms <- tf$math$log(magnitude_spectrograms + 1e-6, 10)
log_magnitude_spectrograms
lms_matrix <- as.matrix(log_magnitude_spectrograms[1,,])
image(z=lms_matrix)
source('C:/Code/Git/PuzzleCounter/test_script.R', echo=TRUE)
source('C:/Code/Git/PuzzleCounter/test_script.R', echo=TRUE)
source('C:/Code/Git/PuzzleCounter/test_script.R', echo=TRUE)
source('C:/Code/Git/PuzzleCounter/test_script.R', echo=TRUE)
source('C:/Code/Git/PuzzleCounter/test_script.R', echo=TRUE)
source('C:/Code/Git/PuzzleCounter/speech_trainer_command_data.R', echo=TRUE)
source('C:/Code/Git/PuzzleCounter/speech_trainer_command_data.R', echo=TRUE)
source('C:/Code/Git/PuzzleCounter/speech_trainer_command_data.R', echo=TRUE)
source('C:/Code/Git/PuzzleCounter/speech_trainer_command_data.R', echo=TRUE)
source('C:/Code/Git/PuzzleCounter/speech_trainer_command_data.R', echo=TRUE)
source('C:/Code/Git/PuzzleCounter/speech_trainer_command_data.R', echo=TRUE)
source('C:/Code/Git/PuzzleCounter/speech_trainer_command_data.R', echo=TRUE)
source('C:/Code/Git/PuzzleCounter/speech_trainer_command_data.R', echo=TRUE)
source('C:/Code/Git/PuzzleCounter/speech_trainer_command_data.R', echo=TRUE)
source('C:/Code/Git/PuzzleCounter/speech_trainer_command_data.R', echo=TRUE)
source('C:/Code/Git/PuzzleCounter/speech_trainer_command_data.R', echo=TRUE)
source('C:/Code/Git/PuzzleCounter/speech_trainer_command_data.R', echo=TRUE)
source('C:/Code/Git/PuzzleCounter/speech_trainer_command_data.R', echo=TRUE)
source('C:/Code/Git/PuzzleCounter/speech_trainer_command_data.R', echo=TRUE)
source('C:/Code/Git/PuzzleCounter/speech_trainer_command_data.R', echo=TRUE)
source('C:/Code/Git/PuzzleCounter/speech_trainer_command_data.R', echo=TRUE)
source('C:/Code/Git/PuzzleCounter/speech_trainer_command_data.R', echo=TRUE)
source('C:/Code/Git/PuzzleCounter/speech_trainer_command_data.R', echo=TRUE)
source('C:/Code/Git/PuzzleCounter/speech_trainer_command_data.R', echo=TRUE)
source('C:/Code/Git/PuzzleCounter/speech_trainer_command_data.R', echo=TRUE)
source('C:/Code/Git/PuzzleCounter/speech_trainer_command_data.R', echo=TRUE)
source('C:/Code/Git/PuzzleCounter/speech_trainer_command_data.R', echo=TRUE)
source('C:/Code/Git/PuzzleCounter/speech_trainer_command_data.R', echo=TRUE)
source('C:/Code/Git/PuzzleCounter/speech_trainer_command_data.R', echo=TRUE)
source('C:/Code/Git/PuzzleCounter/speech_trainer_command_data.R', echo=TRUE)
source('C:/Code/Git/PuzzleCounter/speech_trainer_command_data.R', echo=TRUE)
source('C:/Code/Git/PuzzleCounter/speech_trainer_command_data.R', echo=TRUE)
source('C:/Code/Git/PuzzleCounter/speech_trainer_command_data.R', echo=TRUE)
source('C:/Code/Git/PuzzleCounter/speech_trainer_command_data.R', echo=TRUE)
source('C:/Code/Git/PuzzleCounter/speech_trainer_command_data.R', echo=TRUE)
source('C:/Code/Git/PuzzleCounter/speech_trainer_command_data.R', echo=TRUE)
source('C:/Code/Git/PuzzleCounter/speech_trainer_command_data.R', echo=TRUE)
source('C:/Code/Git/PuzzleCounter/speech_trainer_command_data.R', echo=TRUE)
source('C:/Code/Git/PuzzleCounter/speech_trainer_command_data.R', echo=TRUE)
help(dataset_padded_batch)
source('C:/Code/Git/PuzzleCounter/speech_trainer_command_data.R', echo=TRUE)
source('C:/Code/Git/PuzzleCounter/speech_trainer_command_data.R', echo=TRUE)
n_chunks
n_freq
tf$stack(list(n_chunks, n_freq, -1L))
tf$constant(-1L, shape=shape(1L))
list(tf$stack(list(n_chunks, n_freq, -1L)), tf$constant(-1L, shape=shape(1L))
)
source('C:/Code/Git/PuzzleCounter/speech_trainer_command_data.R', echo=TRUE)
tensorflow::install_tensorflow(version="1.13.1")
source('C:/Code/Git/PuzzleCounter/speech_trainer_command_data.R', echo=TRUE)
source('C:/Code/Git/PuzzleCounter/speech_trainer_command_data.R', echo=TRUE)
source('C:/Code/Git/PuzzleCounter/speech_trainer_command_data.R', echo=TRUE)
source('C:/Code/Git/PuzzleCounter/speech_trainer_command_data.R', echo=TRUE)
source('C:/Code/Git/PuzzleCounter/test_script.R', echo=TRUE)
print(samples)
samples$shape
hold = samples
hold$shape
tf.pad(hold, [[0, 0], [0, 100]], mode='constant')
help(tf$pad)
tf$pad(hold, [[0, 0], [0, 100]], mode='constant')
tf$pad(hold, c(c(0,0),c(0,100)), mode='constant')
source('C:/Code/Git/PuzzleCounter/speech_trainer_command_data.R', echo=TRUE)
source('C:/Code/Git/PuzzleCounter/speech_trainer_command_data.R', echo=TRUE)
print(help)
print(hold)
key = rep(0, 1000)
ouw = tensors_dataset(key)
print(ouw)
ouw = tensors_dataset(key, shape=(1,1000))
key = matrix(0, nrow=1, ncol=1000)
ouw = tensors_dataset(key)
print(ouw)
okay = tf$concat(hold, key, 1L)
okay = tf$concat(list(hold, key), axis=1L)
print(okay)
shape(okay)
okay$shape
okay$shape[[1]]
okay$shape[[1]]==16000
okay$shape[[1]]==11403
source('C:/Code/Git/PuzzleCounter/speech_trainer_command_data.R', echo=TRUE)
source('C:/Code/Git/PuzzleCounter/speech_trainer_command_data.R', echo=TRUE)
source('C:/Code/Git/PuzzleCounter/speech_trainer_command_data.R', echo=TRUE)
source('C:/Code/Git/PuzzleCounter/speech_trainer_command_data.R', echo=TRUE)
source('C:/Code/Git/PuzzleCounter/speech_trainer_command_data.R', echo=TRUE)
source('C:/Code/Git/PuzzleCounter/speech_trainer_command_data.R', echo=TRUE)
source('C:/Code/Git/PuzzleCounter/speech_trainer_command_data.R', echo=TRUE)
source('C:/Code/Git/PuzzleCounter/speech_trainer_command_data.R', echo=TRUE)
source('C:/Code/Git/PuzzleCounter/speech_trainer_command_data.R', echo=TRUE)
source('C:/Code/Git/PuzzleCounter/speech_trainer_command_data.R', echo=TRUE)
source('C:/Code/Git/PuzzleCounter/speech_trainer_command_data.R', echo=TRUE)
source('C:/Code/Git/PuzzleCounter/speech_trainer_command_data.R', echo=TRUE)
source('C:/Code/Git/PuzzleCounter/speech_trainer_command_data.R', echo=TRUE)
